import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

nltk.download('stopwords')
nltk.download('wordnet')

from google.colab import files
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

df = pd.read_csv(file_name, header=None,
                 names=['Tweet_ID', 'Topic', 'Sentiment', 'Tweet'])

df.dropna(subset=['Tweet', 'Sentiment', 'Topic'], inplace=True)

stop = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
def clean_text(text):
    text = re.sub(r'@[\w_]+', '', text)
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'#', '', text)
    text = re.sub(r'[^A-Za-z\s]', '', text)
    tokens = [lemmatizer.lemmatize(w.lower()) for w in text.split() if w.lower() not in stop]
    return ' '.join(tokens)

df['clean_tweet'] = df['Tweet'].apply(clean_text)

plt.figure(figsize=(6, 4))
sns.countplot(x='Sentiment', data=df,
              order=df['Sentiment'].value_counts().index)
plt.title('Overall Sentiment Distribution')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
sns.countplot(x='Topic', hue='Sentiment', data=df,
              order=df['Topic'].value_counts().index)
plt.title('Sentiment by Topic/Brand')
plt.xlabel('Topic/Brand')
plt.ylabel('Tweet Count')
plt.xticks(rotation=45, ha='right')
plt.legend(title='Sentiment')
plt.tight_layout()
plt.show()

for sentiment in df['Sentiment'].unique():
    text = ' '.join(df[df['Sentiment'] == sentiment]['clean_tweet'])
    if not text:
        continue
    wc = WordCloud(width=800, height=400, background_color='white').generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(f'Word Cloud: {sentiment}')
    plt.show()

vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['clean_tweet'])
y = df['Sentiment']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

clf = LogisticRegression(max_iter=200)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
